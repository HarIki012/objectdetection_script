# BHViT: 二值化混合视觉Transformer论文总结 https://arxiv.org/pdf/2503.02394

## 核心思想与主要贡献

本文提出了BHViT（Binarized Hybrid Vision Transformer），这是一种专门为二值化设计的混合视觉Transformer架构。研究发现，直接将现有的二值化CNN技术应用到ViT模型上会导致显著的性能下降，如图1所示，ReActNet在CNN架构上能达到73.3%的准确率，但在ViT架构上仅有49.5%[1]。

主要贡献包括：
- 探索了当前二值化ViT模型性能严重下降的原因[1][2]
- 提出了三个新颖模块构建高性能的二值化友好混合ViT框架[2]
- 提出了基于量化分解(QD)的注意力矩阵二值化方案[2]
- 设计了正则化损失来解决权重振荡与Adam优化器不兼容的问题[2]

## 方法架构

### 1. 混合架构设计
BHViT采用四阶段金字塔结构，在不同阶段使用不同的token mixer[5]：
- **前两个阶段**：使用多尺度分组空洞卷积模块(MSGDC)处理大空间分辨率特征[5]
- **后两个阶段**：使用多尺度多头注意力模块(MSMHA)进行token级特征融合[5]

### 2. 关键技术模块

#### 多尺度分组空洞卷积(MSGDC)
使用三个不同空洞率的3×3分组卷积层，实现多尺度特征融合，显著减少模型参数和计算复杂度[6]。

#### 多尺度多头注意力(MSMHA)
基于窗口注意力机制的变体，通过7×7平均池化获得高尺度特征，同时将输入特征分割为7×7窗口版本，维持全局信息交互并降低计算成本[7]。

#### 量化分解(QD)注意力二值化
针对二值注意力矩阵无法准确表示不同token相似性差异的问题，提出了QD方法。使用全局缩放常数s=2^n-1，通过逻辑操作获得s个二值注意力矩阵[7][8]。

#### 二值化MLP增强
引入shift操作模块，包括水平、垂直和混合shift操作，减轻信息损失和梯度误差[9]。

## 三个重要观察

### 观察1：避免过多token有益于二值化ViT
通过理论分析证明，随着token数量k增加，注意力矩阵的信息熵会增加，概率分布逐渐接近均匀分布，削弱了注意力机制的有效性[6][23][24][25]。

### 观察2：在每个二值化层添加残差连接有益
层级残差连接能有效缓解多个二值化层连续叠加导致的激活梯度消失问题[8][28][29]。

### 观察3：Adam优化器放大了二值网络的权重振荡
在训练后期，Adam优化器会放大权重振荡，导致许多参数无法有效更新。为此提出L1正则化损失[10][30][31]。

## 实验结果

### 分类任务性能
在ImageNet-1K数据集上：
- BHViT-Small†相比当前SOTA方法ReActNet提升20.6%[12]
- 相比Swin transformer架构的BiViT方法提升11.5%[12]
- 在CIFAR-10数据集上，BHViT-Small达到95.0%准确率[11]

### 分割任务性能
在道路分割任务中，BHViT在RS-LVF数据集上的mIoU达到85.1%，超越全精度ResNet-34的77.8%[13]。在ADE20K图像分割任务中也取得了SOTA性能[13]。

## 消融研究

实验验证了各个提出模块的有效性[14]：
- 移除正则化损失导致性能下降2.9%
- 移除shift模块导致性能下降4.3%
- 移除QD方法导致性能下降6.1%

权重分布分析显示，正则化损失能有效改变潜在权重分布，使其更接近±1，缓解权重振荡问题[15]。

## 结论

BHViT成功解决了二值化ViT面临的关键挑战，通过混合架构设计、创新的注意力二值化方法和优化策略，在多个基准数据集上实现了SOTA性能，为在边缘设备上部署高效的视觉Transformer提供了有效解决方案[16]。