# RTDETR剪枝项目介绍

## 对于群里的剪枝相关问题,我基本都会回复,对于一些剪枝问题,我都会给出建议。  

### 首先剪枝是什么？  
模型剪枝是深度学习中的一种技术，旨在通过减少神经网络中不必要的参数和连接，来优化模型的效率和性能。模型剪枝可以分为结构剪枝和参数剪枝两种类型。  

### 为什么需要剪枝？  
剪枝可以很好地衡量模型轻量化程度与精度的关系,是替换轻量化结构完全没办法比的,比如我模型剪枝可以压缩百分之30的计算量,精度只下降了百分之1,但是你通过换模块来达到压缩百分之30的计算量,一般时间就会变长,因为大部分轻量化模块都是由时间换空间,而且精度还会下降得比较多,但是剪枝可以很好地避免这个问题.

### 目前剪枝项目包含以下剪枝方法：
1. L1 
2. Random 
3. Slim(需要稀疏训练)
4. GroupSlim(需要稀疏训练)
5. GroupNorm 
6. LAMP 
7. GroupSL(需要稀疏训练)
8. GroupReg(需要稀疏训练)
9. GroupHessian
10. GroupTaylor

# 对于RTDETR模型，稀疏训练比较难成功，就算能稀疏到模型，掉的精度都比较多，所以我不建议各位使用需要稀疏训练的方法去剪枝，本身RTDETR的训练速度就比较慢，稀疏训练会更加慢一点，所以买剪枝的目的之一一定要需要稀疏训练的方法，那你慎入！！！！！

### 其中prune系列还有一些细节：
1. 支持设定加速比例，模型会进行自动压缩，压缩到指定比例或者达到最大压缩次数后会自动进入finetune。

### 剪枝的一些顾虑
大家关心最多的一个问题就是，我的结构能不能剪之类的，剪枝对模型复杂度的要求比较高，目前剪枝都是基于Torch_Pruning库进行剪枝，prune系列的可以跳过一些不能剪枝的层(某些复杂的结构可能在构建动态图的时候失败,这些就只能换结构)，这个项目会有比较多的示例和视频教程教大家如何去剪自己的结构,注意点在哪里等等。这个剪枝项目是没办法保证所有的结构都能剪，有一定的风险，是否入手请自行考虑！

### 那些人群建议入手剪枝
1. 原始的算法精度很高,没办法再提升精度,只能走轻量化路线,这种建议配合一些轻量化模块+剪枝来增加你的工作量和创新度.
2. 需要部署到嵌入式或者手机端等低算力设备,这类本身模型就不能太复杂,而且以轻量化为主,剪枝是非常适合的.
3. 以后需从事深度学习方面的工作,模型轻量化(蒸馏、量化、剪枝)基本是必须要会的技能.

### RTDETR相关实验 GPU-Device:RTX4090D (以下Model Size为x的实验为我当时记录的数据有点错误，因此直接略掉)
#### Dataset:VisDrone2019 Model:RTDETR-R18
| model | Parameters | GFLOPs | Model Size | mAP50 | mAP50-95 | Inference Time(bs:8) |
| :----: | :----: | :----: | :----: | :----: | :----: | :----: |
| BaseLine | 19,884,600 | 57.0 | x | 0.377 | 0.219 | 0.00305s |
| LAMP exp1 | 13,458,528(67.7%) | 36.6(64.2%) | x | 0.356(-0.021) | 0.205(-0.014) | 0.00247s(81%) |
| LAMP exp2 | 12,279,364(61.7%) | 32.9(57.7%) | x | 0.347(-0.030) | 0.199(-0.020) | 0.00242s(79%) |
| LAMP exp3 | 15,729,152(79.1%) | 43.6(76.5%) | x | 0.366(-0.011) | 0.211(-0.008) | 0.00277s(91%) |
| LAMP exp4 | 14,321,866(72.0%) | 39.1(68.6%) | x | 0.363(-0.014) | 0.21(-0.009) | 0.00260s(85%) |

#### Dataset:CrowdHuman Model:RTDETR-R18
| model | Parameters | GFLOPs | Model Size | mAP50 | mAP50-95 | Inference Time(bs:8) |
| :----: | :----: | :----: | :----: | :----: | :----: | :----: |
| BaseLine | 19,874,328 | 56.9 | x | 0.848 | 0.552 | 0.00306s |
| LAMP exp1 | 14,311,594(72.0%) | 39.1(68.7%) | x | 0.837(-0.011) | 0.543(-0.009) | 0.00259s(85%) |

#### Dataset:Seaship 20%Training Data Model:RTDETR-R18
| model | Parameters | GFLOPs | Model Size | mAP50 | mAP50-95 | Inference Time(bs:8) |
| :----: | :----: | :----: | :----: | :----: | :----: | :----: |
| BaseLine | 19,879,464 | 57.0 | x | 0.951 | 0.73 | 0.00304s |
| LAMP | 7,091,768(35.7%) | 32.1(56.3%) | x | 0.934(-0.017) | 0.73(+0.000) | 0.00239s(79%) |
| L1 | 7,712,000(38.8%) | 33.1(58.1%) | x | 0.935(-0.016) | 0.739(+0.009) | 0.00239s(79%) |
| GROUP_TAYLOR | 1,3160,368(66.2%) | 31.9(55.9%) | x | 0.942(-0.009)	 | 0.734(+0.004) | 0.00212s(70%) |
| GRAOUP_NORM | 9,752,072(49.0%) | 31.7(55.6%) | x | 0.951(0.000) | 0.74(+0.010) | 0.00228s(75%) |
| GRAOUP_HESSIAN | 11,405,392(57.4%) | 31.5(55.3%) | x | 0.94(-0.011) | 0.746(+0.016) | 0.00225s(74%) |
